{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "pd.pandas.set_option(\"display.max_columns\",None)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"CLASSIFIERDATA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"ID\",\"State\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df=df.fillna(method='ffill')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(8,10)})\n",
    "sns.heatmap(data=df.corr(),cmap=\"YlGnBu\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.credit_history)\n",
    "sns.set(rc={\"figure.figsize\":(8,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(7,7)})\n",
    "sns.countplot(x=\"target\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.select_dtypes([np.int,np.float])\n",
    "# for i,col in enumerate(df.columns):\n",
    "#     plt.figure(i)\n",
    "#     sns.boxplot(x=\"credit_history\",y=col,data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_Bucket_dummies=pd.get_dummies(df[\"Age_bucket\"],prefix=\"Age_bucket\")\n",
    "df.drop([\"Age_bucket\"],axis=1,inplace=True)\n",
    "df=pd.concat([df,Age_Bucket_dummies],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"EngineHP_bucket\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EngineHP_bucket_dummies=pd.get_dummies(df[\"EngineHP_bucket\"],prefix=\"EngineHP_bucket\")\n",
    "df.drop([\"EngineHP_bucket\"],axis=1,inplace=True)\n",
    "df=pd.concat([df,EngineHP_bucket_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State_dummies=pd.get_dummies(df[\"State\"],prefix=\"State\")\n",
    "# df.drop([\"State\"],axis=1,inplace=True)\n",
    "# df=pd.concat([df,State_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vehical_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Years_Experience_bucket=pd.get_dummies(df[\"Years_Experience_bucket\"],prefix=\"Years_Experience_bucket\")\n",
    "df.drop(['Years_Experience_bucket'],axis=1,inplace=True)\n",
    "df=pd.concat([df,Years_Experience_bucket],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Miles_driven_annually_bucket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miles_driven_annually_bucket=pd.get_dummies(df[\"Miles_driven_annually_bucket\"],prefix=\"Miles_driven_annually_bucket\")\n",
    "df.drop([\"Miles_driven_annually_bucket\"],axis=1,inplace=True)\n",
    "df=pd.concat([df,Miles_driven_annually_bucket],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "object = preprocessing.LabelEncoder ()\n",
    "df[\"credit_history_bucket\"]=object.fit_transform(df[\"credit_history_bucket\"])\n",
    "print(df[\"credit_history_bucket\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"credit_history_bucket\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"]=df[\"Gender\"].map({\"F\":0,\"M\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Marital_Status\"]=df[\"Marital_Status\"].map({\"Married\":0,\"Single\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Vehical_type\"]=df[\"Vehical_type\"].map({\"Car\":1,\"Truck\":2,\"Van\":3,\"Utility\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of data after all preprocessing ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21396/(21396+8844)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8844/(21396+8844)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop([\"target\"],axis=1)\n",
    "y=df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the 'target' column from training dataframe as that is our label\n",
    "# X = df.drop(['target', 'State'],axis=1)\n",
    "\n",
    "# # The 'target' column is our label or outcome that we want to predict\n",
    "# y = df['target']\n",
    "\n",
    "# # Use pd.dummies to resolve the categorical data (e.g. State) into numerical values\n",
    "# #X = pd.get_dummies(X)\n",
    "\n",
    "# # Drop and NaN values\n",
    "# #X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# os = SMOTE(random_state=0)\n",
    "\n",
    "# columns = x.columns\n",
    "# os_data_x, os_data_y = os.fit_sample(x, y)\n",
    "# os_data_x = pd.DataFrame(data=os_data_x, columns=columns)\n",
    "# os_data_y = pd.DataFrame(data=os_data_y, columns=['y'])\n",
    "\n",
    "# # Split the resulting balanced data set as train and test\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     os_data_X, os_data_y, test_size=0.3, random_state=0)\n",
    "\n",
    "# # Check the size of our new data\n",
    "# print(\"length of oversampled data is \", len(os_data_x))\n",
    "# print(\"Number of negative class in oversampled data\",\n",
    "#       len(os_data_y[os_data_y['y'] == 0]))\n",
    "# print(\"Number of positive class in oversampled data\",\n",
    "#       len(os_data_y[os_data_y['y'] == 1]))\n",
    "# print(\"Proportion of negative class in oversampled data is \",\n",
    "#       len(os_data_y[os_data_y['y'] == 0])/len(os_data_x))\n",
    "# print(\"Proportion of positive class in oversampled data is \",\n",
    "#       len(os_data_y[os_data_y['y'] == 1])/len(os_data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Train Test Split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,train_size=0.6,random_state=12,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train =  x_train.values.reshape(-1,1)     #you want to convert the data in single column\n",
    "# x_test = x_test.values.reshape(-1,1)\n",
    "# y_train =  y_train.values.reshape(-1,1)     #you want to convert the data in single column\n",
    "# y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Standardize the dataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler=StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=scaler.fit_transform(x_train)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train =  x_train.values.reshape(-1,1)     #you want to convert the data in single column\n",
    "# x_test = x_test.values.reshape(-1,1)\n",
    "# y_train =  y_train.values.reshape(-1,1)     #you want to convert the data in single column\n",
    "# y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"target\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_scaled = ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "x_ros, y_ros = ros.fit_resample(x_scaled, y)\n",
    "print(y.value_counts())\n",
    "print(\"############\")\n",
    "print(y_ros.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA####\n",
    "\n",
    "pca = PCA(n_components = 12)\n",
    "df_pca = pca.fit_transform(X=x_ros)    #unsupervised models: fit_transform happens in a single go!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(df_pca)\n",
    "print(df_pca.shape) \n",
    "df_pca.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_ros\n",
    "Y = y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state = 42,train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_met = []\n",
    "list_accuracy = []\n",
    "\n",
    "# Model 1\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(C=0.4, max_iter=1000, solver='liblinear')\n",
    "lr = classifier.fit(x_train, y_train)\n",
    "# Prediction\n",
    "y_pred = classifier.predict(x_test)\n",
    "# Accuarcy\n",
    "accuracy_LR = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Model 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier2 = DecisionTreeClassifier(random_state=14)\n",
    "dt = classifier2.fit(x_train, y_train)\n",
    "# prediction\n",
    "y_pred2 = classifier2.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_DT = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "# Model 3 \n",
    "# criteria - gini\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier3 = RandomForestClassifier(random_state=14)\n",
    "rfi = classifier3.fit(x_train, y_train)\n",
    "#prediction\n",
    "y_pred3 = classifier3.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_RFI = accuracy_score(y_test, y_pred3)\n",
    "\n",
    "# Model 4\n",
    "classifier4 = RandomForestClassifier(criterion='entropy', random_state=14)\n",
    "rfe = classifier4.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred4 = classifier4.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_RFE = accuracy_score(y_test, y_pred4)\n",
    "\n",
    "# Model 5\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC()\n",
    "SVM = model_svm.fit(x_train, y_train)\n",
    "#prediction\n",
    "y_pred5 = model_svm.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_SVC = accuracy_score(y_test, y_pred5)\n",
    "\n",
    "# Model 6\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier()\n",
    "knn = model_knn.fit(x_train, y_train)\n",
    "#prediction\n",
    "pred_knn = model_knn.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_knn = accuracy_score(y_test, pred_knn)\n",
    "\n",
    "# model 7\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(x_train, y_train)\n",
    "# prediction\n",
    "pred_gnb = gnb.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_GNB = accuracy_score(y_test, pred_gnb)\n",
    "\n",
    "# model 8\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "bnb = model.fit(x_train, y_train)\n",
    "# prediction\n",
    "pred_bnb = bnb.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_BNB = accuracy_score(y_test, pred_bnb)\n",
    "\n",
    "# combining all the above model by using voting classifier model\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "evc = VotingClassifier(estimators = [('lr', lr), ('DT', dt), ('RFI', rfi),('RFE', rfe),\n",
    "                                     ('SVC', SVM), ('KNN', knn),('GNB', gnb),\n",
    "                                    ('BNB', bnb)], voting = 'hard',\n",
    "                                    flatten_transform=True)\n",
    "model_evc = evc.fit(x_train, y_train)\n",
    "# prediction\n",
    "pred_evc = evc.predict(x_test)\n",
    "# evaluation\n",
    "accuracy_evc = accuracy_score(y_test, pred_evc)\n",
    "\n",
    "list1 = [\"Logistic Regression\",'Decision Tree','RandomForest Gini', 'RandomForest Entropy',\n",
    "        'Support Vector','K Nearest Neighbors','GuassionNB','BernoulliNB','Voting Classifier']\n",
    "\n",
    "list2 = [accuracy_LR,accuracy_DT,accuracy_RFI,accuracy_RFE,accuracy_SVC,accuracy_knn,\n",
    "        accuracy_GNB,accuracy_BNB, accuracy_evc]\n",
    "\n",
    "list3 = [classifier,classifier2,classifier3,classifier4,model_svm,model_knn,\n",
    "        gnb,model,model_evc]\n",
    "\n",
    "df_accuracy = pd.DataFrame({'Method Used' :list1, \"Accuracy\" :list2})\n",
    "print(df_accuracy)\n",
    "\n",
    "charts = sns.barplot(x='Method Used', y = 'Accuracy', data=df_accuracy)\n",
    "charts.set_xticklabels(charts.get_xticklabels(), rotation=90)\n",
    "print(charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing the different values of hyperparameters\n",
    "model2 = RandomForestClassifier(random_state=64)\n",
    "param_dist = {'max_depth': [2, 3, 4, 8],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                'bootstrap' : [True, False],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Running gridsearchCV to check for all the different PnCs of these parameter values\n",
    "cv_rf = GridSearchCV(model2, cv = 10,\n",
    "                     param_grid=param_dist, verbose = True,\n",
    "                     n_jobs = 3)\n",
    "\n",
    "#Fitting the train set , so that grid search is executed on this dataset\n",
    "cv_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the best parameters by using best_params\n",
    "print('Best Parameters using grid search: \\n', cv_rf.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally the best parameters are specified\n",
    "\n",
    "model2.set_params(criterion = 'gini',\n",
    "                  max_features = None, \n",
    "                  bootstrap = True,\n",
    "                  max_depth = 8)\n",
    "print(\"Training accuracy :\", model.score(x_train, y_train))\n",
    "print(\"Testing accuracy :\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
